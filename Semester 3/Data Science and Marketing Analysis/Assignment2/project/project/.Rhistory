legend(.66,.2,c("According to model","Random selection"),cex=0.8,  col=c("black","blue"), lty=1:2)
text(0.15,1,paste("TDL = ",round(TDL,2), "; GINI = ", round(GINI,2) ))
return(data.frame(TDL,GINI))
}
BaseFormula <- as.formula(SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp + gender + subcategory + articletype)
BaseFormula1 <- as.formula(IsSale ~ SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp + gender + subcategory + articletype)
x.train$SaleStringWithoutConvertingToFactor <- ifelse(x.train$IsSale==1,"Buy","NotBuy")
x.evaluate$SaleStringWithoutConvertingToFactor <- ifelse(x.evaluate$IsSale==1,"Buy","NotBuy")
x.train <- x.train %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
x.evaluate <- x.evaluate %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
Session_logit <- glm(BaseFormula1 , data = x.train, family = "binomial")
#################### Load Training and Validation Set ####################################
#clear workspace
rm(list = ls())
#set working directory
setwd("~/Desktop/Kuliah/Semester 3/Data Science and Marketing Analysis/Assignment2/project/project/final_code")
#load library
library(dplyr)
#load training set
x.train  <- read.csv("datasets/trainingset.csv",header=TRUE)
#load evaluation set
x.evaluate <- read.csv("datasets/evaluationset.csv",header=TRUE)
#convert categorical data to factor
x.train  <- x.train %>%
mutate(gender = as.factor(gender)) %>%
mutate(segment = as.factor(segment)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(maingroup = as.factor(maingroup)) %>%
mutate(articlegroup = as.factor(articlegroup)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
x.evaluate  <- x.evaluate %>%
mutate(gender = as.factor(gender)) %>%
mutate(segment = as.factor(segment)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(maingroup = as.factor(maingroup)) %>%
mutate(articlegroup = as.factor(articlegroup)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
#################### Load Training and Validation Set ####################################
#clear workspace
rm(list = ls())
#set working directory
setwd("~/Desktop/Kuliah/Semester 3/Data Science and Marketing Analysis/Assignment2/project/project/final_code")
#load library
library(dplyr)
#load training set
x.train  <- read.csv("datasets/trainingset.csv",header=TRUE)
#load evaluation set
x.evaluate <- read.csv("datasets/evaluationset.csv",header=TRUE)
#convert categorical data to factor
x.train  <- x.train %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(maingroup = as.factor(maingroup)) %>%
mutate(articlegroup = as.factor(articlegroup)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
x.evaluate  <- x.evaluate %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(maingroup = as.factor(maingroup)) %>%
mutate(articlegroup = as.factor(articlegroup)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
#################### Load Training and Validation Set ####################################
#clear workspace
rm(list = ls())
#set working directory
setwd("~/Desktop/Kuliah/Semester 3/Data Science and Marketing Analysis/Assignment2/project/project/final_code")
#load library
library(dplyr)
#load training set
x.train  <- read.csv("datasets/trainingset.csv",header=TRUE)
#load evaluation set
x.evaluate <- read.csv("datasets/evaluationset.csv",header=TRUE)
#convert categorical data to factor
x.train  <- x.train %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articlegroup = as.factor(articlegroup)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
x.evaluate  <- x.evaluate %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articlegroup = as.factor(articlegroup)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
#################### Load Training and Validation Set ####################################
#clear workspace
rm(list = ls())
#set working directory
setwd("~/Desktop/Kuliah/Semester 3/Data Science and Marketing Analysis/Assignment2/project/project/final_code")
#load library
library(dplyr)
#load training set
x.train  <- read.csv("datasets/trainingset.csv",header=TRUE)
#load evaluation set
x.evaluate <- read.csv("datasets/evaluationset.csv",header=TRUE)
#convert categorical data to factor
x.train  <- x.train %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
x.evaluate  <- x.evaluate %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
makeLiftPlot <- function(Prediction, Evaluate, ModelName){
iPredictionsSorted <- sort(Prediction,index.return=T,decreasing=T)[2]$ix #extract the index order according to predicted retention
CustomersSorted <- Evaluate$SaleString[iPredictionsSorted] #sort the true behavior of customers according to predictions
SumSaleReal<- sum(Evaluate$SaleString == "Buy") #total number of real churners in the evaluation set
CustomerCumulative=seq(nrow(Evaluate))/nrow(Evaluate) #cumulative fraction of customers
SaleCumulative=apply(matrix(CustomersSorted=="Buy"),2,cumsum)/SumSaleReal #cumulative fraction of churners
ProbTD = sum(CustomersSorted[1:floor(nrow(Evaluate)*.1)]=="Buy")/floor(nrow(Evaluate)*.1) #probability of churn in 1st decile
ProbOverall = SumSaleReal / nrow(Evaluate) #overall churn probability
TDL = ProbTD / ProbOverall
GINI = sum((SaleCumulative-CustomerCumulative)/(t(matrix(1,1,nrow(Evaluate))-CustomerCumulative)),na.rm=T)/nrow(Evaluate)
plot(CustomerCumulative,SaleCumulative,type="l",main=paste("Lift curve of", ModelName),xlab="Cumulative fraction of customers (sorted by predicted sale probability)",ylab="Cumulative fraction of buyers")
lines(c(0,1),c(0,1),col="blue",type="l",pch=22, lty=2)
legend(.66,.2,c("According to model","Random selection"),cex=0.8,  col=c("black","blue"), lty=1:2)
text(0.15,1,paste("TDL = ",round(TDL,2), "; GINI = ", round(GINI,2) ))
return(data.frame(TDL,GINI))
}
BaseFormula <- as.formula(SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp + gender + subcategory + articletype)
BaseFormula1 <- as.formula(IsSale ~ SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp + gender + subcategory + articletype)
x.train$SaleStringWithoutConvertingToFactor <- ifelse(x.train$IsSale==1,"Buy","NotBuy")
x.evaluate$SaleStringWithoutConvertingToFactor <- ifelse(x.evaluate$IsSale==1,"Buy","NotBuy")
x.train <- x.train %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
x.evaluate <- x.evaluate %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
Session_logit <- glm(BaseFormula1 , data = x.train, family = "binomial")
BaseFormula <- as.formula(SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp + gender)
BaseFormula1 <- as.formula(IsSale ~ SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp)
Session_logit <- glm(BaseFormula1 , data = x.train, family = "binomial")
Session_logit <- glm(BaseFormula1 , data = as.matrix(x.train), family = "binomial")
Session_logit <- glm(BaseFormula1 , data = x.train.as, family = "binomial")
Session_logit <- glm(BaseFormula1 , data = x.train, family = "binomial")
Session_logit <- glm(BaseFormula1 , data = x.train, family = "binomial")
#################### Load Training and Validation Set ####################################
#clear workspace
rm(list = ls())
#set working directory
setwd("~/Desktop/Kuliah/Semester 3/Data Science and Marketing Analysis/Assignment2/project/project/final_code")
#load library
library(dplyr)
#load training set
x.train  <- read.csv("datasets/trainingset.csv",header=TRUE)
#load evaluation set
x.evaluate <- read.csv("datasets/evaluationset.csv",header=TRUE)
#convert categorical data to factor
x.train  <- x.train %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
x.evaluate  <- x.evaluate %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
makeLiftPlot <- function(Prediction, Evaluate, ModelName){
iPredictionsSorted <- sort(Prediction,index.return=T,decreasing=T)[2]$ix #extract the index order according to predicted retention
CustomersSorted <- Evaluate$SaleString[iPredictionsSorted] #sort the true behavior of customers according to predictions
SumSaleReal<- sum(Evaluate$SaleString == "Buy") #total number of real churners in the evaluation set
CustomerCumulative=seq(nrow(Evaluate))/nrow(Evaluate) #cumulative fraction of customers
SaleCumulative=apply(matrix(CustomersSorted=="Buy"),2,cumsum)/SumSaleReal #cumulative fraction of churners
ProbTD = sum(CustomersSorted[1:floor(nrow(Evaluate)*.1)]=="Buy")/floor(nrow(Evaluate)*.1) #probability of churn in 1st decile
ProbOverall = SumSaleReal / nrow(Evaluate) #overall churn probability
TDL = ProbTD / ProbOverall
GINI = sum((SaleCumulative-CustomerCumulative)/(t(matrix(1,1,nrow(Evaluate))-CustomerCumulative)),na.rm=T)/nrow(Evaluate)
plot(CustomerCumulative,SaleCumulative,type="l",main=paste("Lift curve of", ModelName),xlab="Cumulative fraction of customers (sorted by predicted sale probability)",ylab="Cumulative fraction of buyers")
lines(c(0,1),c(0,1),col="blue",type="l",pch=22, lty=2)
legend(.66,.2,c("According to model","Random selection"),cex=0.8,  col=c("black","blue"), lty=1:2)
text(0.15,1,paste("TDL = ",round(TDL,2), "; GINI = ", round(GINI,2) ))
return(data.frame(TDL,GINI))
}
BaseFormula <- as.formula(SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp + gender + subcategory + articletype)
BaseFormula1 <- as.formula(IsSale ~  views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp + gender + subcategory + articletype)
x.train$SaleStringWithoutConvertingToFactor <- ifelse(x.train$IsSale==1,"Buy","NotBuy")
x.evaluate$SaleStringWithoutConvertingToFactor <- ifelse(x.evaluate$IsSale==1,"Buy","NotBuy")
x.train <- x.train %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
x.evaluate <- x.evaluate %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
Session_logit <- glm(BaseFormula1 , data = x.train, family = "binomial")
summary(Session_logit)
x.evaluate$predictionlogit <- predict(Session_logit, newdata=x.evaluate, type = "response")
x.evaluate$predictionlogitclass[x.evaluate$predictionlogit>.5] <- "Sale"
x.evaluate$predictionlogitclass[x.evaluate$predictionlogit<=.5] <- "NotSale"
x.evaluate$correctlogit <- x.evaluate$predictionlogitclass == x.evaluate$SaleString
print(paste("% of predicted classifications correct", mean(x.evaluate$correctlogit)))
x.evaluate$correctlogit <- x.evaluate$predictionlogitclass == x.evaluate$SaleString
View(x.evaluate)
x.evaluate$predictionlogitclass
x.evaluate$predictionlogit <- predict(Session_logit, newdata=x.evaluate, type = "response")
x.evaluate$predictionlogitclass[x.evaluate$predictionlogit>.5] <- "Buy"
x.evaluate$predictionlogitclass[x.evaluate$predictionlogit<=.5] <- "NotBuy"
x.evaluate$correctlogit <- x.evaluate$predictionlogitclass == x.evaluate$SaleString
print(paste("% of predicted classifications correct", mean(x.evaluate$correctlogit)))
LogitOutput <- makeLiftPlot(x.evaluate$predictionlogit,x.evaluate,"Logit")
########## Neural network ############
library(nnet)
library(caret)
x.modelNNet <- train(BaseFormula, data=x.train, method='nnet', trControl=trainControl(method='cv'))
x.evaluate$predictionNNet <- predict(x.modelNNet, newdata = x.evaluate, type="raw")
x.evaluate$correctNNet <- x.evaluate$predictionNNet == x.evaluate$SaleString
print(paste("% of predicted classifications correct", mean(x.evaluate$correctNNet)))
x.evaluate$probabilitiesNNet <- predict(x.modelNNet, newdata = x.evaluate, type='prob')[,1]
NNetOutput <- makeLiftPlot(x.evaluate$probabilitiesNNet,x.evaluate,"Neural Network")
predict(x.modelNNet, newdata = x.evaluate, type='prob')
x.evaluate$probabilitiesNNet <- predict(x.modelNNet, newdata = x.evaluate, type='prob')[,1]
NNetOutput <- makeLiftPlot(x.evaluate$probabilitiesNNet,x.evaluate,"Neural Network")
install.packages("randomForest")
############ RANDOM FOREST
ptm <- proc.time()
# Create a model using "random forest and bagging ensemble algorithms
library(randomForest)
x.modelRF <- randomForest(BaseFormula, data=x.train, control = cforest_unbiased(mtry = 3))
x.evaluate$predictionRF <- predict(x.modelRF, newdata=x.evaluate, type = "response")
x.evaluate$correctRF <- x.evaluate$predictionRF == x.evaluate$ChurnString
x.evaluate$correctRF <- x.evaluate$predictionRF == x.evaluate$Saletring
x.evaluate$predictionRF
typeof(x.evaluate$predictionRF)
typeof(x.evaluate$Saletring)
x.evaluate$correctRF <- x.evaluate$predictionRF == x.evaluate$SaleString
print(paste("% of predicted classifications correct", mean(x.evaluate$correctRF)))
x.evaluate$probabilitiesRF <- predict(x.modelRF,newdata=x.evaluate,type="prob")[,1]
RFOutput <- makeLiftPlot(x.evaluate$probabilitiesRF,x.evaluate,"Random Forest")
library(dplyr)
library(GGally)
library(lmodel2)
#library(tidyverse)
df = read.csv(file = "datasets/Assignment1_dataset_v3.csv", header = TRUE)
#convert date to date object
df$date <- as.Date(as.factor(df$date),"%Y-%m-%d")
#get the month name from date object
df$month <- format(df$date, "%b")
df$season <- ifelse(df$date >= "2017-01-01" & df$date<"2017-02-28", "winter", ifelse(df$date >= "2017-06-01" & df$date<"2017-07-31", "summer","spring"))
z1 = lm(number_items_sold~TG_avg_temp+FG_avg_wind+SQ_sunshine+RH_precipitation+NG_avg_cloud+UG_humidity, data=df)
z2 = lm(number_items_sold~TG_avg_temp+SQ_sunshine, data=df)
summary(z1)
z2 = lm(number_items_sold~TG_avg_temp+SQ_sunshine, data=df)
summary(z2)
###### Test the regression using ANOVA #######
results = anova(z1, z2)
print(results)
#################### Load Training and Validation Set ####################################
#clear workspace
rm(list = ls())
#set working directory
setwd("~/Desktop/Kuliah/Semester 3/Data Science and Marketing Analysis/Assignment2/project/project/final_code")
#load library
library(dplyr)
#load training set
x.train  <- read.csv("datasets/trainingset.csv",header=TRUE)
#load evaluation set
x.evaluate <- read.csv("datasets/evaluationset.csv",header=TRUE)
#convert categorical data to factor
x.train  <- x.train %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
x.evaluate  <- x.evaluate %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
makeLiftPlot <- function(Prediction, Evaluate, ModelName){
iPredictionsSorted <- sort(Prediction,index.return=T,decreasing=T)[2]$ix #extract the index order according to predicted retention
CustomersSorted <- Evaluate$SaleString[iPredictionsSorted] #sort the true behavior of customers according to predictions
SumSaleReal<- sum(Evaluate$SaleString == "Buy") #total number of real churners in the evaluation set
CustomerCumulative=seq(nrow(Evaluate))/nrow(Evaluate) #cumulative fraction of customers
SaleCumulative=apply(matrix(CustomersSorted=="Buy"),2,cumsum)/SumSaleReal #cumulative fraction of churners
ProbTD = sum(CustomersSorted[1:floor(nrow(Evaluate)*.1)]=="Buy")/floor(nrow(Evaluate)*.1) #probability of churn in 1st decile
ProbOverall = SumSaleReal / nrow(Evaluate) #overall churn probability
TDL = ProbTD / ProbOverall
GINI = sum((SaleCumulative-CustomerCumulative)/(t(matrix(1,1,nrow(Evaluate))-CustomerCumulative)),na.rm=T)/nrow(Evaluate)
plot(CustomerCumulative,SaleCumulative,type="l",main=paste("Lift curve of", ModelName),xlab="Cumulative fraction of customers (sorted by predicted sale probability)",ylab="Cumulative fraction of buyers")
lines(c(0,1),c(0,1),col="blue",type="l",pch=22, lty=2)
legend(.66,.2,c("According to model","Random selection"),cex=0.8,  col=c("black","blue"), lty=1:2)
text(0.15,1,paste("TDL = ",round(TDL,2), "; GINI = ", round(GINI,2) ))
return(data.frame(TDL,GINI))
}
BaseFormula <- as.formula(SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp +SQ_sunshine+ gender + subcategory + articletype)
BaseFormula1 <- as.formula(IsSale ~ SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp +SQ_sunshine+ gender + subcategory + articletype)
x.train$SaleStringWithoutConvertingToFactor <- ifelse(x.train$IsSale==1,"Buy","NotBuy")
x.evaluate$SaleStringWithoutConvertingToFactor <- ifelse(x.evaluate$IsSale==1,"Buy","NotBuy")
x.train <- x.train %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
x.evaluate <- x.evaluate %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
View(x.evaluate)
#################### Load Training and Validation Set ####################################
#clear workspace
rm(list = ls())
#set working directory
setwd("~/Desktop/Kuliah/Semester 3/Data Science and Marketing Analysis/Assignment2/project/project/final_code")
#load library
library(dplyr)
#load training set
x.train  <- read.csv("datasets/trainingset.csv",header=TRUE)
#load evaluation set
x.evaluate <- read.csv("datasets/evaluationset.csv",header=TRUE)
#convert categorical data to factor
x.train  <- x.train %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
x.evaluate  <- x.evaluate %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
makeLiftPlot <- function(Prediction, Evaluate, ModelName){
iPredictionsSorted <- sort(Prediction,index.return=T,decreasing=T)[2]$ix #extract the index order according to predicted retention
CustomersSorted <- Evaluate$SaleString[iPredictionsSorted] #sort the true behavior of customers according to predictions
SumSaleReal<- sum(Evaluate$SaleString == "Buy") #total number of real churners in the evaluation set
CustomerCumulative=seq(nrow(Evaluate))/nrow(Evaluate) #cumulative fraction of customers
SaleCumulative=apply(matrix(CustomersSorted=="Buy"),2,cumsum)/SumSaleReal #cumulative fraction of churners
ProbTD = sum(CustomersSorted[1:floor(nrow(Evaluate)*.1)]=="Buy")/floor(nrow(Evaluate)*.1) #probability of churn in 1st decile
ProbOverall = SumSaleReal / nrow(Evaluate) #overall churn probability
TDL = ProbTD / ProbOverall
GINI = sum((SaleCumulative-CustomerCumulative)/(t(matrix(1,1,nrow(Evaluate))-CustomerCumulative)),na.rm=T)/nrow(Evaluate)
plot(CustomerCumulative,SaleCumulative,type="l",main=paste("Lift curve of", ModelName),xlab="Cumulative fraction of customers (sorted by predicted sale probability)",ylab="Cumulative fraction of buyers")
lines(c(0,1),c(0,1),col="blue",type="l",pch=22, lty=2)
legend(.66,.2,c("According to model","Random selection"),cex=0.8,  col=c("black","blue"), lty=1:2)
text(0.15,1,paste("TDL = ",round(TDL,2), "; GINI = ", round(GINI,2) ))
return(data.frame(TDL,GINI))
}
BaseFormula <- as.formula(SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp +SQ_sunshine+ gender + subcategory + articletype)
BaseFormula1 <- as.formula(IsSale ~ SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp +SQ_sunshine+ gender + subcategory + articletype)
x.train$SaleStringWithoutConvertingToFactor <- ifelse(x.train$IsSale==1,"Buy","NotBuy")
x.evaluate$SaleStringWithoutConvertingToFactor <- ifelse(x.evaluate$IsSale==1,"Buy","NotBuy")
x.train <- x.train %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,SQ_sunshine,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
x.evaluate <- x.evaluate %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,SQ_sunshine,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
#################### Load Training and Validation Set ####################################
#clear workspace
rm(list = ls())
#################### Load Training and Validation Set ####################################
#clear workspace
rm(list = ls())
#set working directory
setwd("~/Desktop/Kuliah/Semester 3/Data Science and Marketing Analysis/Assignment2/project/project/final_code")
#load library
library(dplyr)
#load training set
x.train  <- read.csv("datasets/trainingset.csv",header=TRUE)
#load evaluation set
x.evaluate <- read.csv("datasets/evaluationset.csv",header=TRUE)
View(x.evaluate)
#################### Load Training and Validation Set ####################################
#clear workspace
rm(list = ls())
#set working directory
setwd("~/Desktop/Kuliah/Semester 3/Data Science and Marketing Analysis/Assignment2/project/project/final_code")
#load library
library(dplyr)
#load training set
x.train  <- read.csv("datasets/trainingset.csv",header=TRUE)
#load evaluation set
x.evaluate <- read.csv("datasets/evaluationset.csv",header=TRUE)
#################### Load Training and Validation Set ####################################
#clear workspace
rm(list = ls())
#set working directory
setwd("~/Desktop/Kuliah/Semester 3/Data Science and Marketing Analysis/Assignment2/project/project/final_code")
#load library
library(dplyr)
#load training set
x.train  <- read.csv("datasets/trainingset.csv",header=TRUE)
#load evaluation set
x.evaluate <- read.csv("datasets/evaluationset.csv",header=TRUE)
#convert categorical data to factor
x.train  <- x.train %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
x.evaluate  <- x.evaluate %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
makeLiftPlot <- function(Prediction, Evaluate, ModelName){
iPredictionsSorted <- sort(Prediction,index.return=T,decreasing=T)[2]$ix #extract the index order according to predicted retention
CustomersSorted <- Evaluate$SaleString[iPredictionsSorted] #sort the true behavior of customers according to predictions
SumSaleReal<- sum(Evaluate$SaleString == "Buy") #total number of real churners in the evaluation set
CustomerCumulative=seq(nrow(Evaluate))/nrow(Evaluate) #cumulative fraction of customers
SaleCumulative=apply(matrix(CustomersSorted=="Buy"),2,cumsum)/SumSaleReal #cumulative fraction of churners
ProbTD = sum(CustomersSorted[1:floor(nrow(Evaluate)*.1)]=="Buy")/floor(nrow(Evaluate)*.1) #probability of churn in 1st decile
ProbOverall = SumSaleReal / nrow(Evaluate) #overall churn probability
TDL = ProbTD / ProbOverall
GINI = sum((SaleCumulative-CustomerCumulative)/(t(matrix(1,1,nrow(Evaluate))-CustomerCumulative)),na.rm=T)/nrow(Evaluate)
plot(CustomerCumulative,SaleCumulative,type="l",main=paste("Lift curve of", ModelName),xlab="Cumulative fraction of customers (sorted by predicted sale probability)",ylab="Cumulative fraction of buyers")
lines(c(0,1),c(0,1),col="blue",type="l",pch=22, lty=2)
legend(.66,.2,c("According to model","Random selection"),cex=0.8,  col=c("black","blue"), lty=1:2)
text(0.15,1,paste("TDL = ",round(TDL,2), "; GINI = ", round(GINI,2) ))
return(data.frame(TDL,GINI))
}
BaseFormula <- as.formula(SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp +SQ_sunshine+ gender + subcategory + articletype)
BaseFormula1 <- as.formula(IsSale ~ SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp +SQ_sunshine+ gender + subcategory + articletype)
x.train$SaleStringWithoutConvertingToFactor <- ifelse(x.train$IsSale==1,"Buy","NotBuy")
x.evaluate$SaleStringWithoutConvertingToFactor <- ifelse(x.evaluate$IsSale==1,"Buy","NotBuy")
x.train <- x.train %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,SQ_sunshine,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
x.evaluate <- x.evaluate %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,SQ_sunshine,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
Session_logit <- glm(BaseFormula1 , data = x.train, family = "binomial")
#################### Load Training and Validation Set ####################################
#clear workspace
rm(list = ls())
#set working directory
setwd("~/Desktop/Kuliah/Semester 3/Data Science and Marketing Analysis/Assignment2/project/project/final_code")
#load library
library(dplyr)
#load training set
x.train  <- read.csv("datasets/trainingset.csv",header=TRUE)
#load evaluation set
x.evaluate <- read.csv("datasets/evaluationset.csv",header=TRUE)
#convert categorical data to factor
x.train  <- x.train %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
x.evaluate  <- x.evaluate %>%
mutate(gender = as.factor(gender)) %>%
mutate(subcategory = as.factor(subcategory)) %>%
mutate(articletype = as.factor(articletype)) %>%
mutate(SaleString = as.factor(SaleString))
makeLiftPlot <- function(Prediction, Evaluate, ModelName){
iPredictionsSorted <- sort(Prediction,index.return=T,decreasing=T)[2]$ix #extract the index order according to predicted retention
CustomersSorted <- Evaluate$SaleString[iPredictionsSorted] #sort the true behavior of customers according to predictions
SumSaleReal<- sum(Evaluate$SaleString == "Buy") #total number of real churners in the evaluation set
CustomerCumulative=seq(nrow(Evaluate))/nrow(Evaluate) #cumulative fraction of customers
SaleCumulative=apply(matrix(CustomersSorted=="Buy"),2,cumsum)/SumSaleReal #cumulative fraction of churners
ProbTD = sum(CustomersSorted[1:floor(nrow(Evaluate)*.1)]=="Buy")/floor(nrow(Evaluate)*.1) #probability of churn in 1st decile
ProbOverall = SumSaleReal / nrow(Evaluate) #overall churn probability
TDL = ProbTD / ProbOverall
GINI = sum((SaleCumulative-CustomerCumulative)/(t(matrix(1,1,nrow(Evaluate))-CustomerCumulative)),na.rm=T)/nrow(Evaluate)
plot(CustomerCumulative,SaleCumulative,type="l",main=paste("Lift curve of", ModelName),xlab="Cumulative fraction of customers (sorted by predicted sale probability)",ylab="Cumulative fraction of buyers")
lines(c(0,1),c(0,1),col="blue",type="l",pch=22, lty=2)
legend(.66,.2,c("According to model","Random selection"),cex=0.8,  col=c("black","blue"), lty=1:2)
text(0.15,1,paste("TDL = ",round(TDL,2), "; GINI = ", round(GINI,2) ))
return(data.frame(TDL,GINI))
}
BaseFormula <- as.formula(SaleString ~ views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp +SQ_sunshine+ gender + subcategory + articletype)
BaseFormula1 <- as.formula(IsSale ~  views + remove + carts + birthyear + startyear + numbersearches + avgprice + TG_avg_temp +SQ_sunshine+ gender + subcategory + articletype)
x.train$SaleStringWithoutConvertingToFactor <- ifelse(x.train$IsSale==1,"Buy","NotBuy")
x.evaluate$SaleStringWithoutConvertingToFactor <- ifelse(x.evaluate$IsSale==1,"Buy","NotBuy")
x.train <- x.train %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,SQ_sunshine,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
x.evaluate <- x.evaluate %>% select(views,remove,carts,birthyear,startyear,numbersearches,avgprice,TG_avg_temp,SQ_sunshine,gender,subcategory,articletype,SaleString,IsSale,SaleStringWithoutConvertingToFactor)
Session_logit <- glm(BaseFormula1 , data = x.train, family = "binomial")
summary(Session_logit)
x.evaluate$predictionlogit <- predict(Session_logit, newdata=x.evaluate, type = "response")
x.evaluate$predictionlogitclass[x.evaluate$predictionlogit>.5] <- "Buy"
x.evaluate$predictionlogitclass[x.evaluate$predictionlogit<=.5] <- "NotBuy"
x.evaluate$correctlogit <- x.evaluate$predictionlogitclass == x.evaluate$SaleString
print(paste("% of predicted classifications correct", mean(x.evaluate$correctlogit)))
View(x.train)
LogitOutput <- makeLiftPlot(x.evaluate$predictionlogit,x.evaluate,"Logit")
library(e1071)
x.train[,1:13]
classifier<-naiveBayes(BaseFormula,data=x.train[,1:13])
naiveBayesCorrect <- table(predict(classifier, x.evaluate[,1:12]), x.evaluate[,13])
print(paste("% of predicted classifications correct", sum(diag(naiveBayesCorrect))/sum(naiveBayesCorrect) ))
########## Neural network ############
library(nnet)
library(caret)
x.modelNNet <- train(BaseFormula, data=x.train, method='nnet', trControl=trainControl(method='cv'))
x.evaluate$predictionNNet <- predict(x.modelNNet, newdata = x.evaluate, type="raw")
x.evaluate$correctNNet <- x.evaluate$predictionNNet == x.evaluate$SaleString
print(paste("% of predicted classifications correct", mean(x.evaluate$correctNNet)))
x.evaluate$probabilitiesNNet <- predict(x.modelNNet, newdata = x.evaluate, type='prob')[,1]
NNetOutput <- makeLiftPlot(x.evaluate$probabilitiesNNet,x.evaluate,"Neural Network")
predict(x.modelNNet, newdata = x.evaluate, type='prob')
x.evaluate$probabilitiesNNet <- predict(x.modelNNet, newdata = x.evaluate, type='prob')[,1]
NNetOutput <- makeLiftPlot(x.evaluate$probabilitiesNNet,x.evaluate,"Neural Network")
library(caret)
ptm <- proc.time()
NearN <- knn3(BaseFormula, data=x.train, k=10, prob = FALSE, use.all = TRUE)
x.evaluate$predictionNearN <- predict(NearN, newdata = x.evaluate, type="class")
x.evaluate$correctNearN <- x.evaluate$predictionNearN == x.evaluate$SaleString
print(paste("% of predicted classifications correct", mean(x.evaluate$correctNearN)))
x.evaluate$probabilitiesNearN <- predict(NearN, newdata = x.evaluate, type="prob")[,1]
NNetOutput <- makeLiftPlot(x.evaluate$probabilitiesNNet,x.evaluate,"Neural Network")
NearNOutput <- makeLiftPlot(x.evaluate$probabilitiesNearN,x.evaluate,"Nearest Neighbour")
ptm <- proc.time()
library(rpart)				        # Popular decision tree algorithm
library(rattle)					# Fancy tree plot
library(rpart.plot)				# Enhanced tree plots
library(RColorBrewer)				# Color selection for fancy tree plot
library(party)					# Alternative decision tree algorithm
library(partykit)				# Convert rpart object to BinaryTree
library(caret)					# Just a data source for t
tree.2 <- rpart(BaseFormula,x.train)			# A more reasonable tree
#prp(tree.2)                                 # A fast plot
x.evaluate$predictionTree <- predict(tree.2, newdata = x.evaluate, type = "vector")
x.evaluate$predictionTreeString[x.evaluate$predictionTree==1]="Buy"
x.evaluate$predictionTreeString[x.evaluate$predictionTree==2]="NotBuy"
x.evaluate$correctTree <- x.evaluate$predictionTreeString == x.evaluate$SaleStringWithoutConvertingToFactor
print(paste("% of predicted classifications correct", mean(x.evaluate$correctTree)))
x.evaluate$probabilitiesTree <- predict(tree.2, newdata = x.evaluate, type = "prob")[,1]
TreeOutput <- makeLiftPlot(x.evaluate$probabilitiesTree,x.evaluate,"Tree")
ptm <- proc.time()
library(randomForest)
x.modelRF <- randomForest(BaseFormula, data=x.train, control = cforest_unbiased(mtry = 3))
x.evaluate$predictionRF <- predict(x.modelRF, newdata=x.evaluate, type = "response")
x.evaluate$correctRF <- x.evaluate$predictionRF == x.evaluate$SaleString
print(paste("% of predicted classifications correct", mean(x.evaluate$correctRF)))
typeof(x.evaluate$Saletring)
x.evaluate$probabilitiesRF <- predict(x.modelRF,newdata=x.evaluate,type="prob")[,1]
RFOutput <- makeLiftPlot(x.evaluate$probabilitiesRF,x.evaluate,"Random Forest")
